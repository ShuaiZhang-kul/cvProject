{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c94d258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import average_precision_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb05512c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional block, class satisfied earlier\n",
    "# MAPCallback definition (as before, needed for loading the x.keras model)\n",
    "class MAPCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, train_data, val_data):\n",
    "        super().__init__()\n",
    "        self.tr_ds  = train_data\n",
    "        self.val_ds = val_data\n",
    "    def _compute_map(self, ds):\n",
    "        y_true, y_prob = [], []\n",
    "        for bx, by in ds:\n",
    "            # Ensure bx is a single tensor or list of tensors usable by model.predict\n",
    "            # In this case, bx is likely a batch of images, so it's fine.\n",
    "            y_prob.append(self.model.predict(bx, verbose=0))\n",
    "            # Convert TensorFlow Eager Tensor to NumPy array for y_true\n",
    "            if isinstance(by, tf.Tensor):\n",
    "                 y_true.append(by.numpy())\n",
    "            else: # Handle other potential data types if necessary\n",
    "                 y_true.append(by)\n",
    "        # Check if y_true and y_prob have data before vstack and calculation\n",
    "        if not y_true or not y_prob:\n",
    "             print(\"Warning: No data to compute mAP for the given dataset.\")\n",
    "             return 0.0 # Or raise an error, depending on desired behavior\n",
    "\n",
    "        return average_precision_score(\n",
    "            np.vstack(y_true), np.vstack(y_prob), average=\"macro\")\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        # Note: _compute_map on large datasets inside epoch end can be slow\n",
    "        # and might not be the best practice depending on the use case.\n",
    "        # For this example, keeping it as in the original.\n",
    "        # Also, the attack training loop doesn't use this callback anyway.\n",
    "        logs[\"mAP\"]     = self._compute_map(self.tr_ds)\n",
    "        logs[\"val_mAP\"] = self._compute_map(self.val_ds)\n",
    "        print(f\"\\ntrain mAP: {logs['mAP']:.4f}  \"\n",
    "              f\"val mAP: {logs['val_mAP']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c120585b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained classifier model 'x.keras'...\n",
      "Classifier loaded successfully and set to non-trainable.\n"
     ]
    }
   ],
   "source": [
    "# Optional block, no need import model in production\n",
    "print(\"Loading pre-trained classifier model 'x.keras'...\")\n",
    "try:\n",
    "    classifier = tf.keras.models.load_model(\n",
    "        # '/kaggle/input/x/keras/default/1/x.keras',\n",
    "        'x.keras',\n",
    "        custom_objects={'MAPCallback': MAPCallback, 'BinaryFocalCrossentropy': tf.keras.losses.BinaryFocalCrossentropy}\n",
    "    )\n",
    "    # Set the classifier to non-trainable as it's our fixed target\n",
    "    classifier.trainable = False\n",
    "    print(\"Classifier loaded successfully and set to non-trainable.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading classifier model 'x.keras': {e}\")\n",
    "    # Assuming necessary for the rest of the script\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb1e06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading true labels from /kaggle/input/kul-computer-vision-ga-2-2025/train/train_set.csv...\n",
      "Error: True labels file not found at /kaggle/input/kul-computer-vision-ga-2-2025/train/train_set.csv\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# --- Configuration (Remains mostly the same, maybe structured as a dict/object later) ---\n",
    "# Optional, defined earlier or in other method\n",
    "labels = [\n",
    "    \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\",\n",
    "    \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\",\n",
    "    \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"\n",
    "]\n",
    "# train_dir = '/kaggle/input/kul-computer-vision-ga-2-2025/train/'\n",
    "train_dir = 'kul-computer-vision-ga-2-2025/train/'\n",
    "image_dir = train_dir + 'img/'\n",
    "answer_fpath = train_dir + 'train_set.csv'\n",
    "\n",
    "# Optional, load true labels\n",
    "print(f\"Loading true labels from {answer_fpath}...\")\n",
    "try:\n",
    "    true_labels_df = pd.read_csv(answer_fpath)\n",
    "    true_labels_df.set_index('Id', inplace=True)\n",
    "    true_labels_df = true_labels_df[labels] # Ensure labels list is defined\n",
    "    print(f\"Loaded true labels for {len(true_labels_df)} images.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: True labels file not found at {answer_fpath}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading true labels CSV: {e}\")\n",
    "    exit()\n",
    "\n",
    "# fixed parameters\n",
    "TARGET_HEIGHT = 300\n",
    "TARGET_WIDTH = 300\n",
    "TARGET_CHANNELS = 3 # RGB3, gray-scale1\n",
    "\n",
    "\n",
    "# Adversarial specific config\n",
    "PREDICTION_THRESHOLD = 0.5\n",
    "EPSILON = 0.04      # Êâ∞Âä®ÁöÑÊúÄÂ§ßÂπÖÂ∫¶ (L-infinity norm)\n",
    "GENERATOR_LEARNING_RATE = 1e-4\n",
    "ADVERSARIAL_TRAINING_EPOCHS = 20 # ËÆ≠ÁªÉÁîüÊàêÂô®ÁöÑËΩÆÊï∞\n",
    "ADVERSARIAL_BATCH_SIZE = 16    # ËÆ≠ÁªÉÁîüÊàêÂô®ÁöÑÊâπÂ§ßÂ∞è\n",
    "DATASET_SHUFFLE_BUFFER = 1000 # A reasonable shuffle buffer size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d00c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration (Remains mostly the same, maybe structured as a dict/object later) ---\n",
    "# Optional, defined earlier or in other method\n",
    "labels = [\n",
    "    \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\",\n",
    "    \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\",\n",
    "    \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"\n",
    "]\n",
    "train_dir = '/kaggle/input/kul-computer-vision-ga-2-2025/train/'\n",
    "image_dir = train_dir + 'img/'\n",
    "answer_fpath = train_dir + 'train_set.csv'\n",
    "\n",
    "# Optional, load true labels\n",
    "print(f\"Loading true labels from {answer_fpath}...\")\n",
    "try:\n",
    "    true_labels_df = pd.read_csv(answer_fpath)\n",
    "    true_labels_df.set_index('Id', inplace=True)\n",
    "    true_labels_df = true_labels_df[labels] # Ensure labels list is defined\n",
    "    print(f\"Loaded true labels for {len(true_labels_df)} images.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: True labels file not found at {answer_fpath}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading true labels CSV: {e}\")\n",
    "    exit()\n",
    "\n",
    "# fixed parameters\n",
    "TARGET_HEIGHT = 300\n",
    "TARGET_WIDTH = 300\n",
    "TARGET_CHANNELS = 3 # RGB3, gray-scale1\n",
    "\n",
    "\n",
    "# Adversarial specific config\n",
    "PREDICTION_THRESHOLD = 0.5\n",
    "EPSILON = 0.04      # Êâ∞Âä®ÁöÑÊúÄÂ§ßÂπÖÂ∫¶ (L-infinity norm)\n",
    "GENERATOR_LEARNING_RATE = 1e-4\n",
    "ADVERSARIAL_TRAINING_EPOCHS = 20 # ËÆ≠ÁªÉÁîüÊàêÂô®ÁöÑËΩÆÊï∞\n",
    "ADVERSARIAL_BATCH_SIZE = 16    # ËÆ≠ÁªÉÁîüÊàêÂô®ÁöÑÊâπÂ§ßÂ∞è\n",
    "DATASET_SHUFFLE_BUFFER = 1000 # A reasonable shuffle buffer size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ff9e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdversarialGenerator(tf.keras.Model):\n",
    "    def __init__(self, input_shape, num_channels_output, epsilon):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.conv1 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')\n",
    "        self.conv2 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')\n",
    "        self.conv_output = tf.keras.layers.Conv2D(num_channels_output, (3, 3), padding='same', activation='tanh')\n",
    "        # Lambda layer to scale the tanh output by epsilon\n",
    "        # This layer scales the perturbation base [-1, 1] to [-epsilon, epsilon]\n",
    "        self.epsilon_scaler = tf.keras.layers.Lambda(lambda t: t * self.epsilon)\n",
    "\n",
    "        self.build((None,) + input_shape)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.conv2(x)\n",
    "        perturbation_base = self.conv_output(x)\n",
    "        # Apply the epsilon scaling\n",
    "        perturbation = self.epsilon_scaler(perturbation_base)\n",
    "        return perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8a5c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional, preprocessor\n",
    "class ImageDataProcessor:\n",
    "    def __init__(self, image_dir, true_labels_df, labels, target_height, target_width, target_channels):\n",
    "        self.image_dir = image_dir\n",
    "        self.true_labels_df = true_labels_df\n",
    "        self.labels = labels\n",
    "        self.target_height = target_height\n",
    "        self.target_width = target_width\n",
    "        self.target_channels = target_channels\n",
    "\n",
    "        # Internal lists to store processed data and corresponding IDs/paths\n",
    "        self._processed_images = None\n",
    "        self._processed_labels = None\n",
    "        self._processed_ids = None\n",
    "        self._relevant_files_info = None # Stores (id, path, label_array) tuples\n",
    "\n",
    "    def _find_relevant_files(self):\n",
    "        \"\"\"Finds image files that have corresponding true labels.\"\"\"\n",
    "        if self._relevant_files_info is not None:\n",
    "            return self._relevant_files_info # Return cached info if available\n",
    "\n",
    "        relevant_files_info = []\n",
    "        print(f\"Searching for relevant image files in {self.image_dir}...\")\n",
    "        # Iterate through files in the image directory\n",
    "        for filename in sorted(os.listdir(self.image_dir)):\n",
    "            # Check if filename matches the pattern train_ID.npy\n",
    "            if filename.startswith(\"train_\") and filename.endswith(\".npy\"):\n",
    "                # Extract ID\n",
    "                image_id_str = filename[len(\"train_\"):-len(\".npy\")]\n",
    "                try:\n",
    "                    image_id_int = int(image_id_str)\n",
    "                except ValueError:\n",
    "                    # Skip if ID is not a valid integer\n",
    "                    continue\n",
    "                # Check if the ID exists in the true labels DataFrame\n",
    "                if image_id_int in self.true_labels_df.index:\n",
    "                    file_path = os.path.join(self.image_dir, filename)\n",
    "                    # Get the corresponding true label array\n",
    "                    label_val = self.true_labels_df.loc[image_id_int, self.labels].values.astype(np.float32)\n",
    "                    relevant_files_info.append((image_id_int, file_path, label_val))\n",
    "\n",
    "        if not relevant_files_info:\n",
    "            print(\"Warning: No relevant image files with matching labels found.\")\n",
    "        else:\n",
    "             print(f\"Found {len(relevant_files_info)} relevant image files.\")\n",
    "\n",
    "        self._relevant_files_info = relevant_files_info # Cache the result\n",
    "        return relevant_files_info\n",
    "\n",
    "    def _load_and_preprocess_single_image(self, file_path):\n",
    "        \"\"\"Loads and preprocesses a single .npy image file.\"\"\"\n",
    "        try:\n",
    "            # Load numpy data from the file path\n",
    "            img_data = np.load(file_path)\n",
    "        except Exception as e:\n",
    "            # Print error and return None if loading fails\n",
    "            print(f\"Error loading .npy file {file_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "        # Handle potential extra batch dimension (shape [1, H, W, C])\n",
    "        if img_data.ndim == 4 and img_data.shape[0] == 1:\n",
    "            img_data = img_data[0]\n",
    "        # Check if the dimensions are correct (H, W, C)\n",
    "        elif img_data.ndim != 3:\n",
    "            print(f\"Skipping {file_path}: Unexpected data dimension {img_data.ndim}. Expected 3 (H,W,C) or 4 (1,H,W,C).\")\n",
    "            return None\n",
    "\n",
    "        # Convert to TensorFlow Tensor and resize to target dimensions\n",
    "        # Use method='area' or 'bilinear' depending on preference, 'area' is often good for downsampling\n",
    "        img_data_resized = tf.image.resize(img_data, [self.target_height, self.target_width], method='area')\n",
    "\n",
    "        # Handle channel mismatch if target_channels is specified\n",
    "        current_channels = img_data_resized.shape[-1]\n",
    "        if current_channels != self.target_channels:\n",
    "            # Convert grayscale (1 channel) to RGB (3 channels) if needed\n",
    "            if current_channels == 1 and self.target_channels == 3:\n",
    "                img_data_resized = tf.image.grayscale_to_rgb(img_data_resized)\n",
    "            # Convert RGB (3 channels) to grayscale (1 channel) if needed\n",
    "            elif self.target_channels == 1 and current_channels == 3:\n",
    "                 img_data_resized = tf.image.rgb_to_grayscale(img_data_resized)\n",
    "            else:\n",
    "                # Skip if channel conversion is not supported or possible\n",
    "                print(f\"Skipping {file_path}: Channel mismatch. Processed {current_channels} vs Target {self.target_channels}.\")\n",
    "                return None\n",
    "\n",
    "        # Cast to float32 type for consistency with model input\n",
    "        img_data_resized = tf.cast(img_data_resized, tf.float32)\n",
    "\n",
    "        # Normalize pixel values if they are in the 0-255 range\n",
    "        max_val = tf.reduce_max(img_data_resized)\n",
    "        # Check if max_val is significantly greater than 1.0\n",
    "        if max_val > 1.0 + 1e-6:\n",
    "            min_val = tf.reduce_min(img_data_resized)\n",
    "            # Assume 0-255 range if min is near 0 and max is near 255\n",
    "            if min_val >= 0 and max_val <= 255.0 + 1e-6 :\n",
    "                 img_data_resized = img_data_resized / 255.0\n",
    "            # Optional: Add warnings or other normalization logic for different ranges\n",
    "            # else:\n",
    "            #     print(f\"Warning: Image {file_path} has max value {max_val} but not clearly in 0-255 range. Check normalization.\")\n",
    "\n",
    "        # Clip values to the [0.0, 1.0] range after normalization\n",
    "        img_data_resized = tf.clip_by_value(img_data_resized, 0.0, 1.0)\n",
    "\n",
    "        # Return the processed image tensor\n",
    "        return img_data_resized\n",
    "\n",
    "    def process_all_relevant_data(self):\n",
    "        \"\"\"Loads and preprocesses all relevant images and stores them.\"\"\"\n",
    "        if self._processed_images is not None:\n",
    "            print(\"Using cached processed data.\")\n",
    "            # Return cached data\n",
    "            return self._processed_images, self._processed_labels, self._processed_ids\n",
    "\n",
    "        print(\"Starting to process all relevant images...\")\n",
    "        # Find the list of relevant files first\n",
    "        relevant_files = self._find_relevant_files()\n",
    "\n",
    "        # Initialize lists to store processed data\n",
    "        processed_images = []\n",
    "        processed_labels = []\n",
    "        processed_ids = []\n",
    "\n",
    "        # Iterate through the relevant files list\n",
    "        for image_id, file_path, label_val in relevant_files:\n",
    "            # Load and preprocess the single image\n",
    "            img = self._load_and_preprocess_single_image(file_path)\n",
    "            # Check if processing was successful and the shape matches the target\n",
    "            if img is not None and img.shape[-3:] == (self.target_height, self.target_width, self.target_channels):\n",
    "                # Append to the lists\n",
    "                processed_images.append(img)\n",
    "                processed_labels.append(label_val)\n",
    "                processed_ids.append(image_id)\n",
    "            elif img is not None:\n",
    "                 # Print warning for shape mismatch after processing\n",
    "                 print(f\"Skipping image {file_path} due to shape mismatch after processing: {img.shape} vs {(self.target_height, self.target_width, self.target_channels)}\")\n",
    "\n",
    "        # Check if any images were successfully processed\n",
    "        if not processed_images:\n",
    "            print(\"Error: No images could be successfully processed.\")\n",
    "            # Consider raising an exception here if no data is critical\n",
    "            self._processed_images, self._processed_labels, self._processed_ids = [], [], []\n",
    "            return [], [], [] # Return empty lists\n",
    "        else:\n",
    "            print(f\"Successfully processed {len(processed_images)} images.\")\n",
    "            # Store the processed data\n",
    "            # Convert lists of Tensors/Arrays to NumPy arrays for tf.data.Dataset.from_tensor_slices efficiency\n",
    "            self._processed_images = np.array(processed_images)\n",
    "            self._processed_labels = np.array(processed_labels)\n",
    "            self._processed_ids = processed_ids # Keep IDs as a list\n",
    "\n",
    "            return self._processed_images, self._processed_labels, self._processed_ids\n",
    "\n",
    "    def get_training_dataset(self, batch_size, shuffle_buffer_size=None):\n",
    "        \"\"\"Creates and returns a TensorFlow Dataset for training.\"\"\"\n",
    "        # Ensure data is processed before creating the dataset\n",
    "        images, labels, _ = self.process_all_relevant_data()\n",
    "\n",
    "        if not images.size: # Check if the numpy array is not empty\n",
    "             print(\"Cannot create dataset: No processed data available.\")\n",
    "             return None\n",
    "\n",
    "        # Create dataset from the processed NumPy arrays\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "\n",
    "        # Apply shuffling if buffer size is specified\n",
    "        if shuffle_buffer_size is not None:\n",
    "            dataset = dataset.shuffle(buffer_size=shuffle_buffer_size)\n",
    "\n",
    "        # Apply batching and prefetching\n",
    "        dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bbe811",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdversarialAttackExecutor:\n",
    "    def __init__(self, classifier_model, generator_model, optimizer_g, loss_fn, epsilon, prediction_threshold):\n",
    "        self.classifier = classifier_model\n",
    "        self.generator = generator_model\n",
    "        self.optimizer_g = optimizer_g\n",
    "        self.loss_fn = loss_fn # Should be a loss function compatible with classifier output and true labels\n",
    "        self.epsilon = epsilon # Store epsilon for reference, generator already uses it\n",
    "        self.prediction_threshold = prediction_threshold\n",
    "\n",
    "        # Ensure classifier is not trainable\n",
    "        self.classifier.trainable = False\n",
    "\n",
    "    def train_generator(self, train_dataset, epochs):\n",
    "        \"\"\"Trains the adversarial generator.\"\"\"\n",
    "        if train_dataset is None:\n",
    "            print(\"Error: Training dataset is not available. Cannot train generator.\")\n",
    "            return\n",
    "\n",
    "        print(\"\\nStarting adversarial training for the generator...\")\n",
    "        # Iterate through training epochs\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "            epoch_g_loss = 0.0 # Initialize total generator loss for this epoch\n",
    "            num_batches = 0   # Initialize batch counter\n",
    "\n",
    "            # Iterate through batches in the training dataset\n",
    "            for original_images_batch, true_labels_batch in train_dataset:\n",
    "                # Use tf.GradientTape to record operations for automatic differentiation\n",
    "                with tf.GradientTape() as tape:\n",
    "                    # Generate perturbations using the generator model\n",
    "                    # training=True is passed but might not change behavior for this generator structure\n",
    "                    perturbations = self.generator(original_images_batch, training=True)\n",
    "\n",
    "                    # Create adversarial images by adding perturbations to original images\n",
    "                    adversarial_images = original_images_batch + perturbations\n",
    "                    # Clip the adversarial images to the valid range [0.0, 1.0]\n",
    "                    # This ensures pixels stay within image boundaries\n",
    "                    adversarial_images = tf.clip_by_value(adversarial_images, 0.0, 1.0)\n",
    "\n",
    "                    # Get predictions from the fixed classifier on the adversarial images\n",
    "                    # training=False because the classifier is not being trained\n",
    "                    predictions_adversarial = self.classifier(adversarial_images, training=False)\n",
    "\n",
    "                    # Calculate the generator's loss\n",
    "                    # The generator wants to MAXIMIZE the classifier's loss\n",
    "                    # (i.e., make the classifier predict incorrectly)\n",
    "                    # So, the generator's loss is the NEGATIVE of the classifier's loss\n",
    "                    # This way, minimizing generator loss corresponds to maximizing classifier loss\n",
    "                    # Ensure predictions_adversarial and true_labels_batch are compatible with self.loss_fn\n",
    "                    adv_loss = -self.loss_fn(true_labels_batch, predictions_adversarial)\n",
    "\n",
    "                # Compute gradients of the adversarial loss with respect to the generator's trainable variables\n",
    "                gradients_g = tape.gradient(adv_loss, self.generator.trainable_variables)\n",
    "\n",
    "                # Apply the gradients to update the generator's weights\n",
    "                self.optimizer_g.apply_gradients(zip(gradients_g, self.generator.trainable_variables))\n",
    "\n",
    "                # Accumulate the batch loss\n",
    "                # Ensure adv_loss is a scalar or handle reduction correctly\n",
    "                epoch_g_loss += adv_loss.numpy()\n",
    "                num_batches += 1\n",
    "\n",
    "            # Calculate and print the average generator loss for the epoch\n",
    "            avg_epoch_g_loss = epoch_g_loss / num_batches if num_batches > 0 else 0\n",
    "            print(f\"  Generator loss: {avg_epoch_g_loss:.4f}\")\n",
    "\n",
    "        print(\"Finished adversarial training for the generator.\")\n",
    "\n",
    "    def generate_adversarial_predictions(self, relevant_files_info, data_processor_instance):\n",
    "        \"\"\"Generates adversarial predictions for a list of image files.\"\"\"\n",
    "        print(\"\\nGenerating adversarial examples and evaluating the original classifier on them...\")\n",
    "        predictions_dict_adversarial = {} # Dictionary to store predictions (binary labels) {id: [labels]}\n",
    "        processed_ids_adversarial = []   # List to store IDs for which predictions were generated\n",
    "\n",
    "        # Iterate through the list of relevant files (ID, path, label)\n",
    "        for image_id_int, file_path, _ in relevant_files_info: # We only need ID and path here\n",
    "\n",
    "            try:\n",
    "                # Load and preprocess the original image using the provided processor instance\n",
    "                # This reuses the preprocessing logic defined in ImageDataProcessor\n",
    "                original_img_processed = data_processor_instance._load_and_preprocess_single_image(file_path)\n",
    "                # Skip if preprocessing failed or returned None\n",
    "                if original_img_processed is None:\n",
    "                    continue\n",
    "\n",
    "                # Add a batch dimension to the processed image (H, W, C) -> (1, H, W, C)\n",
    "                original_img_batch = tf.expand_dims(original_img_processed, axis=0)\n",
    "                # Ensure it's float32, though preprocessing should handle this\n",
    "                original_img_batch = tf.cast(original_img_batch, tf.float32)\n",
    "\n",
    "                # Use the trained generator to predict the perturbation\n",
    "                # training=False in evaluation mode\n",
    "                perturbation_batch = self.generator(original_img_batch, training=False)\n",
    "\n",
    "                # Create the adversarial image\n",
    "                adversarial_image_batch = original_img_batch + perturbation_batch\n",
    "                # Clip values to ensure they are within the valid [0.0, 1.0] range\n",
    "                adversarial_image_batch = tf.clip_by_value(adversarial_image_batch, 0.0, 1.0)\n",
    "\n",
    "                # Get predictions from the classifier on the adversarial image\n",
    "                predictions_adv = self.classifier.predict(adversarial_image_batch, verbose=0)\n",
    "\n",
    "                # Check if the prediction output shape matches the number of labels\n",
    "                if predictions_adv.shape[-1] == len(labels): # Check last dim of output shape\n",
    "                    # Convert probability predictions to binary labels using the threshold\n",
    "                    predicted_binary_adv = (predictions_adv[0] > self.prediction_threshold).astype(int)\n",
    "                    # Store the prediction result in the dictionary\n",
    "                    predictions_dict_adversarial[image_id_int] = predicted_binary_adv\n",
    "                    # Add the image ID to the list of processed IDs\n",
    "                    processed_ids_adversarial.append(image_id_int)\n",
    "                # else:\n",
    "                #     print(f\"Skipping {file_path}: Classifier output shape {predictions_adv.shape} doesn't match expected label count.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                # Print error for any exception during processing or prediction\n",
    "                print(f\"Error processing {file_path} for adversarial evaluation: {e}\")\n",
    "\n",
    "        print(f\"Finished generating adversarial predictions for {len(processed_ids_adversarial)} files.\")\n",
    "        # Return the dictionary of predictions and the list of processed IDs\n",
    "        return predictions_dict_adversarial, processed_ids_adversarial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5a291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Setting up Adversarial Attack ---\")\n",
    "\n",
    "# 1. Instantiate the Generator Model\n",
    "# Pass input shape and epsilon\n",
    "generator = AdversarialGenerator(\n",
    "    input_shape=(TARGET_HEIGHT, TARGET_WIDTH, TARGET_CHANNELS),\n",
    "    num_channels_output=TARGET_CHANNELS,\n",
    "    epsilon=EPSILON\n",
    ")\n",
    "\n",
    "# 2. Define Optimizer and Loss for Generator Training\n",
    "optimizer_g = tf.keras.optimizers.Adam(learning_rate=GENERATOR_LEARNING_RATE)\n",
    "# The loss function is the classifier's loss function\n",
    "# Note: In the original code, this was BinaryFocalCrossentropy.\n",
    "# Let's define it here, matching the one used by the classifier.\n",
    "# Ensure from_logits matches the classifier's output (False means sigmoid output)\n",
    "# The reduction strategy should match how you want to average loss over the batch\n",
    "# SUM_OVER_BATCH_SIZE means sum losses for all items in batch, then divide by batch size\n",
    "classifier_loss_fn = tf.keras.losses.BinaryFocalCrossentropy(\n",
    "    from_logits=False,\n",
    "    reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE\n",
    ")\n",
    "\n",
    "\n",
    "# 3. Instantiate the Data Processor\n",
    "data_processor = ImageDataProcessor(\n",
    "    image_dir=image_dir,\n",
    "    true_labels_df=true_labels_df, # Pass the loaded dataframe\n",
    "    labels=labels,                 # Pass the labels list\n",
    "    target_height=TARGET_HEIGHT,\n",
    "    target_width=TARGET_WIDTH,\n",
    "    target_channels=TARGET_CHANNELS\n",
    ")\n",
    "\n",
    "# 4. Prepare the Training Dataset\n",
    "# This calls internal methods to find files, preprocess, and create the dataset\n",
    "train_dataset_gen = data_processor.get_training_dataset(\n",
    "    batch_size=ADVERSARIAL_BATCH_SIZE,\n",
    "    shuffle_buffer_size=DATASET_SHUFFLE_BUFFER # Using defined buffer size\n",
    ")\n",
    "\n",
    "# Check if dataset creation was successful\n",
    "if train_dataset_gen is None:\n",
    "    print(\"Failed to prepare training dataset. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# 5. Instantiate the Adversarial Attack Executor\n",
    "attack_executor = AdversarialAttackExecutor(\n",
    "    classifier_model=classifier,\n",
    "    generator_model=generator,\n",
    "    optimizer_g=optimizer_g,\n",
    "    loss_fn=classifier_loss_fn, # Pass the classifier's loss function\n",
    "    epsilon=EPSILON, # Pass epsilon (mostly for reference)\n",
    "    prediction_threshold=PREDICTION_THRESHOLD # Pass the threshold for later evaluation\n",
    ")\n",
    "\n",
    "# 6. Train the Generator\n",
    "attack_executor.train_generator(\n",
    "    train_dataset=train_dataset_gen,\n",
    "    epochs=ADVERSARIAL_TRAINING_EPOCHS\n",
    ")\n",
    "\n",
    "# 7. Generate Adversarial Predictions\n",
    "# Get the list of relevant files (IDs and paths) from the data processor\n",
    "relevant_files_for_pred = data_processor._find_relevant_files() # Use the internal list\n",
    "\n",
    "# Generate predictions on adversarial examples\n",
    "predictions_dict_adversarial, processed_ids_adversarial = attack_executor.generate_adversarial_predictions(\n",
    "    relevant_files_info=relevant_files_for_pred,\n",
    "    data_processor_instance=data_processor # Pass the processor instance for loading/preprocessing\n",
    ")\n",
    "\n",
    "# 8. Evaluate the Attack (Calculate accuracy on adversarial examples)\n",
    "# This part remains outside the executor class as it's a separate evaluation step\n",
    "# using the results generated by the executor and the original true labels.\n",
    "valid_processed_ids_adv = [\n",
    "    id_val for id_val in processed_ids_adversarial\n",
    "    if id_val in predictions_dict_adversarial and id_val in true_labels_df.index\n",
    "]\n",
    "\n",
    "if not valid_processed_ids_adv:\n",
    "    print(\"\\nNo valid adversarial predictions with matching true labels stored. Cannot calculate accuracy on adversarial examples.\")\n",
    "else:\n",
    "    print(f\"\\nCalculating accuracy on adversarial examples for {len(valid_processed_ids_adv)} images...\")\n",
    "    valid_processed_ids_adv.sort() # Sort IDs for consistent order\n",
    "\n",
    "    # Extract true labels and predicted labels for the valid IDs\n",
    "    true_matrices_list_adv = [true_labels_df.loc[id_val, labels].values for id_val in valid_processed_ids_adv]\n",
    "    predicted_matrices_list_adv = [predictions_dict_adversarial[id_val] for id_val in valid_processed_ids_adv]\n",
    "\n",
    "    true_matrix_adv = np.array(true_matrices_list_adv)\n",
    "    predicted_matrix_adv = np.array(predicted_matrices_list_adv)\n",
    "\n",
    "    # Perform shape and emptiness checks before calculating accuracy\n",
    "    if true_matrix_adv.shape != predicted_matrix_adv.shape:\n",
    "        print(f\"Error: Shape mismatch for adversarial data. True: {true_matrix_adv.shape}, Pred: {predicted_matrix_adv.shape}\")\n",
    "    elif true_matrix_adv.size == 0:\n",
    "        print(\"Error: Adversarial true/predicted matrices are empty after filtering.\")\n",
    "    else:\n",
    "        num_images_adv, num_labels_adv = true_matrix_adv.shape\n",
    "        print(f\"Comparing true and predicted (adversarial) labels for {num_images_adv} images and {num_labels_adv} classes.\")\n",
    "\n",
    "        print(\"\\n--- Per-Class Accuracy (Adversarial) ---\")\n",
    "        # Calculate and print per-class accuracy\n",
    "        for i, label_name in enumerate(labels):\n",
    "            true_col_adv = true_matrix_adv[:, i]\n",
    "            predicted_col_adv = predicted_matrix_adv[:, i]\n",
    "            # Accuracy for a class is (TP + TN) / Total Samples\n",
    "            correct_predictions_for_class_adv = (true_col_adv == predicted_col_adv).sum()\n",
    "            accuracy_adv = correct_predictions_for_class_adv / num_images_adv if num_images_adv > 0 else 0\n",
    "            print(f\"Accuracy for '{label_name}' (adversarial): {accuracy_adv:.4f}\")\n",
    "\n",
    "        print(\"\\n--- Overall (Micro) Accuracy (Adversarial) ---\")\n",
    "        # Calculate and print overall micro accuracy (accuracy across all individual label predictions)\n",
    "        total_correct_predictions_adv = (true_matrix_adv == predicted_matrix_adv).sum()\n",
    "        total_possible_predictions_adv = float(true_matrix_adv.size)\n",
    "        overall_accuracy_adv = total_correct_predictions_adv / total_possible_predictions_adv if total_possible_predictions_adv > 0 else 0\n",
    "        print(f\"Overall (Micro) Accuracy (Adversarial): {overall_accuracy_adv:.4f}\")\n",
    "\n",
    "print(\"\\n--- Adversarial Attack Block Finished ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7f269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_visualizations = 5\n",
    "\n",
    "# Ensure there are valid processed IDs to visualize\n",
    "if not valid_processed_ids_adv:\n",
    "    print(\"No valid adversarial examples generated to visualize.\")\n",
    "else:\n",
    "    # Select a few random IDs from the list of successfully processed adversarial examples\n",
    "    # Using np.random.choice ensures uniqueness and handles cases where num_visualizations > list length\n",
    "    ids_to_visualize = np.random.choice(valid_processed_ids_adv,\n",
    "                                        min(num_visualizations, len(valid_processed_ids_adv)),\n",
    "                                        replace=False)\n",
    "\n",
    "    print(f\"Visualizing {len(ids_to_visualize)} random examples...\")\n",
    "\n",
    "    # Get the list of relevant files info from the data processor (it's cached after processing)\n",
    "    relevant_files_info = data_processor._find_relevant_files()\n",
    "    # Create a dictionary mapping ID to (path, label) for quick lookup\n",
    "    relevant_files_dict = {id_: (path, label) for id_, path, label in relevant_files_info}\n",
    "\n",
    "    # Iterate through the selected IDs\n",
    "    for image_id in ids_to_visualize:\n",
    "        print(f\"\\nVisualizing Image ID: {image_id}\")\n",
    "\n",
    "        # Get file path and true label for this ID\n",
    "        file_path, true_label_array = relevant_files_dict.get(image_id)\n",
    "        if file_path is None:\n",
    "             print(f\"Could not find file info for ID {image_id}, skipping.\")\n",
    "             continue\n",
    "\n",
    "        # Get the adversarial prediction for this ID\n",
    "        adv_prediction_array = predictions_dict_adversarial.get(image_id)\n",
    "        if adv_prediction_array is None:\n",
    "             print(f\"Could not find adversarial prediction for ID {image_id}, skipping.\")\n",
    "             continue\n",
    "\n",
    "        try:\n",
    "            # Load and preprocess the original image using the processor instance\n",
    "            original_img_processed = data_processor._load_and_preprocess_single_image(file_path)\n",
    "\n",
    "            if original_img_processed is None:\n",
    "                print(f\"Preprocessing failed for ID {image_id}, skipping visualization.\")\n",
    "                continue\n",
    "\n",
    "            # Ensure the image is in the expected float32 format and has the correct shape\n",
    "            if not isinstance(original_img_processed, tf.Tensor) or original_img_processed.dtype != tf.float32:\n",
    "                 original_img_processed = tf.cast(original_img_processed, tf.float32)\n",
    "\n",
    "            # Generate adversarial image (using the trained generator)\n",
    "            # Add batch dimension (H, W, C) -> (1, H, W, C)\n",
    "            original_img_batch = tf.expand_dims(original_img_processed, axis=0)\n",
    "\n",
    "            # Use the trained generator from the attack executor\n",
    "            perturbation_batch = attack_executor.generator(original_img_batch, training=False)\n",
    "\n",
    "            # Create adversarial image\n",
    "            adversarial_image_batch = original_img_batch + perturbation_batch\n",
    "            # Clip values back to [0.0, 1.0]\n",
    "            adversarial_image_batch = tf.clip_by_value(adversarial_image_batch, 0.0, 1.0)\n",
    "\n",
    "            # Convert Tensors to NumPy arrays for plotting and remove batch dimension\n",
    "            original_img_np = tf.squeeze(original_img_batch, axis=0).numpy()\n",
    "            adversarial_img_np = tf.squeeze(adversarial_image_batch, axis=0).numpy()\n",
    "            perturbation_np = tf.squeeze(perturbation_batch, axis=0).numpy() # Optional: visualize perturbation too\n",
    "\n",
    "            # --- Plotting ---\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(12, 6)) # 1 row, 2 columns\n",
    "\n",
    "            # Plot Original Image\n",
    "            axes[0].imshow(original_img_np)\n",
    "            axes[0].set_title(\"Original Image\")\n",
    "            axes[0].axis('off') # Hide axes ticks and labels\n",
    "\n",
    "            # Plot Adversarial Image\n",
    "            axes[1].imshow(adversarial_img_np)\n",
    "            axes[1].set_title(\"Adversarial Image\")\n",
    "            axes[1].axis('off') # Hide axes ticks and labels\n",
    "\n",
    "            # --- Add Title with Labels/Predictions ---\n",
    "            # Format true labels and adversarial predictions\n",
    "            true_labels_str = [labels[i] for i, val in enumerate(true_label_array) if val == 1]\n",
    "            adv_pred_str = [labels[i] for i, val in enumerate(adv_prediction_array) if val == 1]\n",
    "\n",
    "            # Compare and highlight prediction changes\n",
    "            comparison_str = []\n",
    "            for i, label_name in enumerate(labels):\n",
    "                true_val = true_label_array[i]\n",
    "                pred_val = adv_prediction_array[i]\n",
    "                if true_val == 1 and pred_val == 1:\n",
    "                    comparison_str.append(f\"‚úÖ{label_name}\") # Correctly predicted positive\n",
    "                elif true_val == 1 and pred_val == 0:\n",
    "                    comparison_str.append(f\"‚ùå{label_name}\") # Missed positive\n",
    "                elif true_val == 0 and pred_val == 1:\n",
    "                     comparison_str.append(f\"üö®{label_name}\") # False positive (attack success for this label)\n",
    "                # If true_val is 0 and pred_val is 0, it's a correct negative, usually less interesting for attack visualization\n",
    "                # Optionally include: elif true_val == 0 and pred_val == 0: comparison_str.append(f\"‚ö™{label_name}\")\n",
    "\n",
    "            main_title = f\"ID: {image_id} | True: [{', '.join(true_labels_str)}] | Adv Pred (Threshold={PREDICTION_THRESHOLD}): [{', '.join(adv_pred_str)}]\\nComparison: [{', '.join(comparison_str)}]\"\n",
    "            fig.suptitle(main_title, y=1.02) # Add a super title slightly above the plots\n",
    "\n",
    "            plt.tight_layout(rect=[0, 0, 1, 0.98]) # Adjust layout to prevent title overlap\n",
    "            plt.show() # Display the figure\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during visualization for ID {image_id}: {e}\")\n",
    "            # Continue to the next image even if one fails"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
